{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67eca65d",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681229d",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db3673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torchmetrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72ee66",
   "metadata": {},
   "source": [
    "### Creating a Tensor from a List Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d8e4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define temperature object\n",
    "temperatures = [[72, 75, 78], [70, 73, 76]]\n",
    "\n",
    "# Create a tensor from temperatures\n",
    "temp_tensor = torch.tensor(temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f6a80",
   "metadata": {},
   "source": [
    "### Update a Tensor Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an adjustment object\n",
    "adjustment = torch.tensor([[2, 2, 2], [2, 2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61230cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the temperatures tensor\n",
    "temp_shape = temperatures.shape\n",
    "print(\"Shape of temperatures:\", temp_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of the temperatures tensor\n",
    "temp_type = temperatures.dtype\n",
    "print(\"Data type of temperatures:\", temp_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3308028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of temperatures: torch.Size([2, 3])\n",
      "Data type of temperatures: torch.int64\n",
      "Corrected temperatures: tensor([[74, 77, 80],\n",
      "        [72, 75, 78]])\n"
     ]
    }
   ],
   "source": [
    "# Adjust the temperatures by adding the adjustment tensor\n",
    "corrected_temperatures = temperatures + adjustment\n",
    "print(\"Corrected temperatures:\", corrected_temperatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51622d",
   "metadata": {},
   "source": [
    "### Create a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with two linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 10),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69756c",
   "metadata": {},
   "source": [
    "### Understanding Activation Functions\n",
    "\n",
    "1. Sigmoid Activation Function: Used for binary classification\n",
    "\n",
    "2. Softmax Activation Function: Used for multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafea796",
   "metadata": {},
   "source": [
    "### Sigmoid Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb74ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[0.8]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ee9ce",
   "metadata": {},
   "source": [
    "### Softmax Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcf295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax()\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23494bc9",
   "metadata": {},
   "source": [
    "### Understanding the Training Loop\n",
    "\n",
    "1. Propogate data forward\n",
    "2. Compare outputs to truth values\n",
    "3. Backpropogate to update weights and biases\n",
    "4. Repeat until weights and biases are tuned to produce meaningful results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab78196",
   "metadata": {},
   "source": [
    "### Create a neural network for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b0452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9846]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b694e7a5",
   "metadata": {},
   "source": [
    "### Create a 4-layer linear neural network compatible with input_tensor as the input, and a regression value as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d103cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0244]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 12),\n",
    "    nn.Linear(12, 12),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f406fe",
   "metadata": {},
   "source": [
    "### Update the network provided to perform a multi-class classification with four outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec5a5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2008, 0.2121, 0.2682, 0.3189]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae7c46",
   "metadata": {},
   "source": [
    "### One hot encoding for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "438eccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([1, 0, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f7313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbac10bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbb939",
   "metadata": {},
   "source": [
    "### Loss function for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f966f1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881df7d",
   "metadata": {},
   "source": [
    "### Accessing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ceb973",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2),\n",
    "                      nn.Linear(2, 1)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895ed1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0324, -0.2304, -0.1966,  0.0474,  0.1192, -0.1544, -0.0386,  0.1083,\n",
       "         -0.0328,  0.2341, -0.0540,  0.1825, -0.2004, -0.1325, -0.2104,  0.2037],\n",
       "        [ 0.1631, -0.1088, -0.1084, -0.2179, -0.0978,  0.2385,  0.1869,  0.0953,\n",
       "          0.1931, -0.0958,  0.2163,  0.1586,  0.0521,  0.1915,  0.1213,  0.0454],\n",
       "        [-0.1163, -0.0294, -0.0318, -0.2401,  0.1443,  0.0830, -0.2296,  0.2451,\n",
       "         -0.0003, -0.0443, -0.2326,  0.0659, -0.1015,  0.0506, -0.2281, -0.1605],\n",
       "        [-0.0925,  0.1461, -0.2062, -0.0906,  0.1633,  0.0283,  0.0614, -0.1515,\n",
       "         -0.2156, -0.1510, -0.0919,  0.1340,  0.0415, -0.1377, -0.0786, -0.2489],\n",
       "        [ 0.0309,  0.1957, -0.0772, -0.2007,  0.0206,  0.2474, -0.1179,  0.0868,\n",
       "         -0.2385, -0.1134, -0.1803, -0.1949, -0.2072,  0.1195, -0.0040,  0.1377],\n",
       "        [ 0.1394, -0.1626, -0.2166,  0.1050, -0.0863,  0.0698,  0.1126,  0.1403,\n",
       "         -0.1128, -0.1202,  0.1676, -0.0717, -0.1589, -0.0641, -0.2094,  0.2407],\n",
       "        [-0.0689,  0.2245, -0.2082, -0.1700, -0.0276,  0.1302,  0.1517, -0.0769,\n",
       "          0.2452,  0.2156,  0.0982,  0.0475, -0.1366, -0.1546,  0.0460, -0.2397],\n",
       "        [-0.1014,  0.1671, -0.2014,  0.1249,  0.1798, -0.2005,  0.0846, -0.1932,\n",
       "         -0.0413,  0.0419, -0.0508, -0.2457, -0.0060,  0.2271,  0.2152,  0.1389]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e14e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2324, -0.2417], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54bf90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.001\n",
    "\n",
    "# weight0 = model[0].weight\n",
    "# weight1 = model[1].weight\n",
    "# weight2 = model[2].weight\n",
    "\n",
    "# # Access the gradients of the weight of each linear layer\n",
    "# grads0 = weight0.grad\n",
    "# grads1 = weight1.grad\n",
    "# grads2 = weight2.grad\n",
    "\n",
    "# # Update the weights using the learning rate and the gradients\n",
    "# weight0 = weight0 - lr * grads0\n",
    "# weight1 = weight1 - lr * grads1\n",
    "# weight2 = weight2 - lr * grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss = criterion(pred, target)\n",
    "loss.backward()\n",
    "\n",
    "# Update the model's parameters using the optimizer\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52a7ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.mean((y_pred - y)**2)\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_pred).float(), torch.tensor(y).float())\n",
    "print(mse_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36de8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "907a2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the number of epochs and the dataloader\n",
    "# for i in range(num_epochs):\n",
    "    \n",
    "#     for data in dataloader:\n",
    "#         # Set the gradients to zero\n",
    "#         optimizer.zero_grad()\n",
    "#         # Run a forward pass\n",
    "#         feature, target = data\n",
    "#         prediction = model(feature)    \n",
    "#         # Calculate the loss\n",
    "#         loss = criterion(prediction, target)    \n",
    "#         # Compute the gradients\n",
    "#         loss.backward()\n",
    "#         # Update the model's parameters\n",
    "#         optimizer.step()\n",
    "    \n",
    "# show_results(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29a3c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14b7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 4),\n",
    "                      nn.Linear(4, 2),\n",
    "                      nn.Linear(2, 1))\n",
    "\n",
    "total = 0\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "  \n",
    "print(f\"The number of parameters in the model is {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca32da8",
   "metadata": {},
   "source": [
    "Create a 4-layer linear neural network with >120 parameters, using n_features as input and n_classes as output sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with more than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 16),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 3), \n",
    "    nn.Linear(3, n_classes)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae19814",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c032fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "np_features = np.array(np.random.rand(12, 8))\n",
    "np_target = np.array(np.random.rand(12, 1))\n",
    "\n",
    "torch_features = torch.tensor(np_features)\n",
    "torch_target = torch.tensor(np_target)\n",
    "\n",
    "# Create a TensorDataset from two tensors\n",
    "dataset = TensorDataset(torch_features.float(), torch_target.float())\n",
    "\n",
    "# Return the last element of this dataset\n",
    "print(dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e752850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\n",
    "target = torch.tensor(dataframe['Potability'].to_numpy()).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 4),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "output = model(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b18e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "validation_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "  \n",
    "    for data in validationloader:\n",
    "    \n",
    "        outputs = model(data[0])\n",
    "        loss = criterion(outputs, data[1])\n",
    "      \n",
    "        # Sum the current loss to the validation_loss variable\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "# Calculate the mean loss value\n",
    "validation_loss_epoch = validation_loss / len(validationloader)\n",
    "print(validation_loss_epoch)\n",
    "\n",
    "# Set the model back to training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bacd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac9aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy metric using torch metrics\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "for data in dataloader:\n",
    "    features, labels = data\n",
    "    outputs = model(features)\n",
    "    \n",
    "    # Calculate accuracy over the batch\n",
    "    acc = metric(outputs, labels.argmax(dim=-1))\n",
    "    \n",
    "# Calculate accuracy over the whole epoch\n",
    "acc = metric.compute()\n",
    "\n",
    "# Reset the metric for the next epoch \n",
    "metric.reset()\n",
    "plot_errors(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f678dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same model, set the dropout probability to 0.8\n",
    "model = nn.Sequential(nn.Linear(3072, 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.8))\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362bb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for idx in range(10):\n",
    "    # Randomly sample a learning rate factor between 2 and 4\n",
    "    factor = np.random.uniform(2,4)\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    # Randomly select a momentum between 0.85 and 0.99\n",
    "    momentum = np.random.uniform(0.85, 0.99)\n",
    "    \n",
    "    values.append((lr, momentum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f408d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cce6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4b2221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7a35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d992a80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_venv",
   "language": "python",
   "name": "learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
