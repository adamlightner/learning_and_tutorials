{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa96b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "\n",
    "temperatures = [[72, 75, 78], [70, 73, 76]]\n",
    "\n",
    "# Create a tensor from temperatures\n",
    "temp_tensor = torch.tensor(temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a26e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of temperatures: torch.Size([2, 3])\n",
      "Data type of temperatures: torch.int64\n",
      "Corrected temperatures: tensor([[74, 77, 80],\n",
      "        [72, 75, 78]])\n"
     ]
    }
   ],
   "source": [
    "temperatures = torch.tensor([[72, 75, 78], [70, 73, 76]])\n",
    "adjustment = torch.tensor([[2, 2, 2], [2, 2, 2]])\n",
    "\n",
    "# Check the shape of the temperatures tensor\n",
    "temp_shape = temperatures.shape\n",
    "print(\"Shape of temperatures:\", temp_shape)\n",
    "\n",
    "# Check the type of the temperatures tensor\n",
    "temp_type = temperatures.dtype\n",
    "print(\"Data type of temperatures:\", temp_type)\n",
    "\n",
    "# Adjust the temperatures by adding the adjustment tensor\n",
    "corrected_temperatures = temperatures + adjustment\n",
    "\n",
    "print(\"Corrected temperatures:\", corrected_temperatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input_tensor = torch.Tensor([[2, 3, 6, 7, 9, 3, 2, 1]])\n",
    "\n",
    "# Implement a small neural network with two linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 10),\n",
    "    nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09068f66",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function: Used for binary classification\n",
    "\n",
    "### Softmax Activation Function: Used for multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b23e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[0.8]])\n",
    "\n",
    "# Create a sigmoid function and apply it on input_tensor\n",
    "sigmoid = nn.Sigmoid()\n",
    "probability = sigmoid(input_tensor)\n",
    "print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([[1.0, -6.0, 2.5, -0.3, 1.2, 0.8]])\n",
    "\n",
    "# Create a softmax function and apply it on input_tensor\n",
    "softmax = nn.Softmax()\n",
    "probabilities = softmax(input_tensor)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07956116",
   "metadata": {},
   "source": [
    "In the training loop, we: \n",
    "\n",
    "1. Propogate data forward\n",
    "2. Compare outputs to truth values\n",
    "3. Backpropogate to update weights and biases\n",
    "4. Repeat until weights and biases are tuned to produce meaningful results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08751a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0292]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a small neural network for binary classification\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3ab86",
   "metadata": {},
   "source": [
    "Create a 4-layer linear neural network compatible with input_tensor as the input, and a regression value as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40224c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Implement a neural network with exactly four linear layers\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 12),\n",
    "    nn.Linear(12, 12),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065b120",
   "metadata": {},
   "source": [
    "Update the network provided to perform a multi-class classification with four outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006f7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2008, 0.2121, 0.2682, 0.3189]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[3, 4, 6, 7, 10, 12, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Update network below to perform a multi-class classification with four labels\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(11, 20),\n",
    "  nn.Linear(20, 12),\n",
    "  nn.Linear(12, 6),\n",
    "  nn.Linear(6, 4), \n",
    "  nn.Softmax()\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd70184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efd59ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b1e929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([1, 0, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2fb32fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e6351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa712a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54347179",
   "metadata": {},
   "source": [
    "### Accessing the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acb5fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2),\n",
    "                      nn.Linear(2, 1)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d41e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.1266, -0.1751,  0.1399,  0.0688,  0.2230,  0.0831,  0.1882,  0.1348,\n",
       "           0.0803, -0.1993, -0.2427,  0.2148, -0.2220,  0.1736,  0.1757, -0.1004],\n",
       "         [-0.0540,  0.1005, -0.0686, -0.0669,  0.2124,  0.1541, -0.1146,  0.1207,\n",
       "           0.2491, -0.0730, -0.2478, -0.2126,  0.0149,  0.0389,  0.1063,  0.0214],\n",
       "         [-0.2469,  0.0112,  0.2362,  0.0835,  0.1824, -0.2401, -0.1568, -0.2191,\n",
       "          -0.2046, -0.1876, -0.0402, -0.0487, -0.1378,  0.1416, -0.2055,  0.1901],\n",
       "         [ 0.1929, -0.1599,  0.1892, -0.0746, -0.1819,  0.0885,  0.1846,  0.1947,\n",
       "           0.0768, -0.0791, -0.2101,  0.0204, -0.0868,  0.0633, -0.2065, -0.1019],\n",
       "         [-0.0597,  0.1160,  0.0674,  0.1675,  0.0646,  0.1461,  0.2106,  0.1274,\n",
       "           0.0432,  0.0563, -0.1968, -0.0648, -0.2463,  0.0735, -0.1699, -0.0628],\n",
       "         [ 0.2234,  0.2487,  0.2219, -0.1028,  0.0164,  0.2418, -0.1116,  0.0468,\n",
       "          -0.0236,  0.1092, -0.1454,  0.1638, -0.1760, -0.0945, -0.0361,  0.0029],\n",
       "         [ 0.0377,  0.1508,  0.1291,  0.1791,  0.1539,  0.1784,  0.2081,  0.2490,\n",
       "           0.2036, -0.0052, -0.1292, -0.0146,  0.0093,  0.1325, -0.0826, -0.1269],\n",
       "         [ 0.1454,  0.1356,  0.2373,  0.0443, -0.1893,  0.0206,  0.0609, -0.1633,\n",
       "           0.0525,  0.0265,  0.1789,  0.1827,  0.1770, -0.0992, -0.0529, -0.1980]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3265,  0.2072], requires_grad=True))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_0, bias_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d451b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.001\n",
    "\n",
    "# weight0 = model[0].weight\n",
    "# weight1 = model[1].weight\n",
    "# weight2 = model[2].weight\n",
    "\n",
    "# # Access the gradients of the weight of each linear layer\n",
    "# grads0 = weight0.grad\n",
    "# grads1 = weight1.grad\n",
    "# grads2 = weight2.grad\n",
    "\n",
    "# # Update the weights using the learning rate and the gradients\n",
    "# weight0 = weight0 - lr * grads0\n",
    "# weight1 = weight1 - lr * grads1\n",
    "# weight2 = weight2 - lr * grads2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b704bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loss = criterion(pred, target)\n",
    "loss.backward()\n",
    "\n",
    "# Update the model's parameters using the optimizer\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f195b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(81.)\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(10)\n",
    "y = np.array(1)\n",
    "\n",
    "# Calculate the MSELoss using NumPy\n",
    "mse_numpy = np.mean((y_pred - y)**2)\n",
    "\n",
    "# Create the MSELoss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Calculate the MSELoss using the created loss function\n",
    "mse_pytorch = criterion(torch.tensor(y_pred).float(), torch.tensor(y).float())\n",
    "print(mse_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd6f434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eccf27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the number of epochs and the dataloader\n",
    "# for i in range(num_epochs):\n",
    "    \n",
    "#     for data in dataloader:\n",
    "#         # Set the gradients to zero\n",
    "#         optimizer.zero_grad()\n",
    "#         # Run a forward pass\n",
    "#         feature, target = data\n",
    "#         prediction = model(feature)    \n",
    "#         # Calculate the loss\n",
    "#         loss = criterion(prediction, target)    \n",
    "#         # Compute the gradients\n",
    "#         loss.backward()\n",
    "#         # Update the model's parameters\n",
    "#         optimizer.step()\n",
    "    \n",
    "# show_results(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ReLU function with PyTorch\n",
    "relu_pytorch = nn.ReLU()\n",
    "\n",
    "# Apply your ReLU function on x, and calculate gradients\n",
    "x = torch.tensor(-1.0, requires_grad=True)\n",
    "y = relu_pytorch(x)\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient of the ReLU function for x\n",
    "gradient = x.grad\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a leaky relu function in PyTorch\n",
    "leaky_relu_pytorch = nn.LeakyReLU(negative_slope=0.05)\n",
    "\n",
    "x = torch.tensor(-2.0)\n",
    "# Call the above function on the tensor x\n",
    "output = leaky_relu_pytorch(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c15fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 4),\n",
    "                      nn.Linear(4, 2),\n",
    "                      nn.Linear(2, 1))\n",
    "\n",
    "total = 0\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "for parameter in model.parameters():\n",
    "    total += parameter.numel()\n",
    "  \n",
    "print(f\"The number of parameters in the model is {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085937fe",
   "metadata": {},
   "source": [
    "Create a 4-layer linear neural network with >120 parameters, using n_features as input and n_classes as output sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce627115",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 8\n",
    "n_classes = 2\n",
    "\n",
    "input_tensor = torch.Tensor([[3, 4, 6, 2, 3, 6, 8, 9]])\n",
    "\n",
    "# Create a neural network with more than 120 parameters\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 16),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.Linear(8, 3), \n",
    "    nn.Linear(3, n_classes)\n",
    ")\n",
    "\n",
    "output = model(input_tensor)\n",
    "\n",
    "print(calculate_capacity(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef15440",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():    \n",
    "  \n",
    "    # Check if the parameters belong to the first layer\n",
    "    if name == '0.weight' or name == '0.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False\n",
    "  \n",
    "    # Check if the parameters belong to the second layer\n",
    "    if name == '1.weight' or name == '1.bias':\n",
    "      \n",
    "        # Freeze the parameters\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = nn.Linear(16, 32)\n",
    "layer1 = nn.Linear(32, 64)\n",
    "\n",
    "# Use uniform initialization for layer0 and layer1 weights\n",
    "nn.init.uniform_(layer0.weight)\n",
    "nn.init.uniform_(layer1.weight)\n",
    "\n",
    "model = nn.Sequential(layer0, layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1c4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "np_features = np.array(np.random.rand(12, 8))\n",
    "np_target = np.array(np.random.rand(12, 1))\n",
    "\n",
    "torch_features = torch.tensor(np_features)\n",
    "torch_target = torch.tensor(np_target)\n",
    "\n",
    "# Create a TensorDataset from two tensors\n",
    "dataset = TensorDataset(torch_features.float(), torch_target.float())\n",
    "\n",
    "# Return the last element of this dataset\n",
    "print(dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the different columns into two PyTorch tensors\n",
    "features = torch.tensor(dataframe[['ph', 'Sulfate', 'Conductivity', 'Organic_carbon']].to_numpy()).float()\n",
    "target = torch.tensor(dataframe['Potability'].to_numpy()).float()\n",
    "\n",
    "# Create a dataset from the two generated tensors\n",
    "dataset = TensorDataset(features, target)\n",
    "\n",
    "# Create a dataloader using the above dataset\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n",
    "x, y = next(iter(dataloader))\n",
    "\n",
    "# Create a model using the nn.Sequential API\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 4),\n",
    "    nn.Linear(4, 1)\n",
    ")\n",
    "output = model(features)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600323c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "validation_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "  \n",
    "    for data in validationloader:\n",
    "    \n",
    "        outputs = model(data[0])\n",
    "        loss = criterion(outputs, data[1])\n",
    "      \n",
    "        # Sum the current loss to the validation_loss variable\n",
    "        validation_loss += loss.item()\n",
    "        \n",
    "# Calculate the mean loss value\n",
    "validation_loss_epoch = validation_loss / len(validationloader)\n",
    "print(validation_loss_epoch)\n",
    "\n",
    "# Set the model back to training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e725a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148835e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy metric using torch metrics\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "for data in dataloader:\n",
    "    features, labels = data\n",
    "    outputs = model(features)\n",
    "    \n",
    "    # Calculate accuracy over the batch\n",
    "    acc = metric(outputs, labels.argmax(dim=-1))\n",
    "    \n",
    "# Calculate accuracy over the whole epoch\n",
    "acc = metric.compute()\n",
    "\n",
    "# Reset the metric for the next epoch \n",
    "metric.reset()\n",
    "plot_errors(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72818737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the same model, set the dropout probability to 0.8\n",
    "model = nn.Sequential(nn.Linear(3072, 16),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(p=0.8))\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9077ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for idx in range(10):\n",
    "    # Randomly sample a learning rate factor between 2 and 4\n",
    "    factor = np.random.uniform(2,4)\n",
    "    lr = 10 ** -factor\n",
    "    \n",
    "    # Randomly select a momentum between 0.85 and 0.99\n",
    "    momentum = np.random.uniform(0.85, 0.99)\n",
    "    \n",
    "    values.append((lr, momentum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f221a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fabee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44cc478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb83cbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21641c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fb0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355cf1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning_venv",
   "language": "python",
   "name": "learning_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
